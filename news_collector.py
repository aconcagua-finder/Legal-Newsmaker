#!/usr/bin/env python3
"""
News Collector –¥–ª—è NEWSMAKER

–ú–æ–¥—É–ª—å –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ —Å–±–æ—Ä–∞ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ Perplexity Deep Research
–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Ö –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏.
"""

import json
import os
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, Dict, List
from loguru import logger

import config
from perplexity_client import PerplexityClient
from openai_client import OpenAIClient
from prompts import (
    get_perplexity_daily_collection_prompt,
    get_perplexity_system_prompt,
    parse_collected_news,
    PromptConfig
)


class NewsCollector:
    """–ö–æ–ª–ª–µ–∫—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ —Å–±–æ—Ä–∞ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
    
    def __init__(self):
        self.perplexity_client = PerplexityClient()
        self.openai_client = OpenAIClient()
        self.data_dir = Path(config.DATA_DIR)
        self.data_dir.mkdir(exist_ok=True)
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        self.images_dir = self.data_dir / "images"
        self.images_dir.mkdir(exist_ok=True)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Å–±–æ—Ä–∞
        self.max_retries = 3
        self.retry_delay = 60  # 1 –º–∏–Ω—É—Ç–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏
    
    def _get_news_file_path(self, date: datetime) -> Path:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∞—Ç—ã
        
        Args:
            date: –î–∞—Ç–∞ –¥–ª—è —Ñ–∞–π–ª–∞ –Ω–æ–≤–æ—Å—Ç–µ–π
            
        Returns:
            Path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        """
        date_str = date.strftime('%Y-%m-%d')
        filename = config.NEWS_FILE_PATTERN.format(date=date_str)
        return self.data_dir / filename
    
    def _get_image_file_path(self, date: datetime, news_id: str) -> Path:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –Ω–æ–≤–æ—Å—Ç–∏
        
        Args:
            date: –î–∞—Ç–∞ –Ω–æ–≤–æ—Å—Ç–∏
            news_id: ID –Ω–æ–≤–æ—Å—Ç–∏
            
        Returns:
            Path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        date_str = date.strftime('%Y-%m-%d')
        date_images_dir = self.images_dir / date_str
        date_images_dir.mkdir(exist_ok=True)
        return date_images_dir / f"{news_id}.png"
    
    def _generate_images_for_news(self, news_list: List[Dict], target_date: datetime) -> List[Dict]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –¥–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–µ–π
        
        Args:
            news_list: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π
            target_date: –î–∞—Ç–∞ –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏—è –ø–∞–ø–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            
        Returns:
            List[Dict]: –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
        """
        if not self.openai_client or not self.openai_client.client:
            logger.warning("üé® OpenAI –∫–ª–∏–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            return news_list
        
        logger.info("üé® –ù–∞—á–∏–Ω–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –≤—Å–µ—Ö –Ω–æ–≤–æ—Å—Ç–µ–π...")
        
        updated_news_list = []
        total_news = len(news_list)
        
        for i, news_item in enumerate(news_list, 1):
            news_id = news_item.get('id', f'news_{i}')
            title = news_item.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
            content = news_item.get('content', '')
            
            logger.info(f"üñºÔ∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {i}/{total_news}: {title[:50]}...")
            
            try:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                image_bytes = self.openai_client.generate_comic_image(content)
                
                if image_bytes:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
                    image_path = self._get_image_file_path(target_date, news_id)
                    
                    with open(image_path, 'wb') as f:
                        f.write(image_bytes)
                    
                    # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –¥–ª—è JSON
                    relative_image_path = str(image_path.relative_to(Path.cwd()))
                    
                    logger.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {image_path.name}")
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –≤ –Ω–æ–≤–æ—Å—Ç—å
                    news_item.update({
                        'image_path': relative_image_path,
                        'image_generated': True,
                        'image_size': len(image_bytes)
                    })
                else:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è: {title[:30]}...")
                    news_item.update({
                        'image_path': None,
                        'image_generated': False,
                        'image_error': '–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å'
                    })
                    
            except Exception as e:
                logger.error(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è {title[:30]}...: {e}")
                news_item.update({
                    'image_path': None,
                    'image_generated': False,
                    'image_error': str(e)
                })
            
            updated_news_list.append(news_item)
        
        successful_images = sum(1 for news in updated_news_list if news.get('image_generated', False))
        logger.info(f"üéâ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {successful_images}/{total_news} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —É—Å–ø–µ—à–Ω–æ")
        
        return updated_news_list
    
    def _cleanup_old_files(self):
        """–£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã –Ω–æ–≤–æ—Å—Ç–µ–π"""
        try:
            cutoff_date = datetime.now() - timedelta(days=config.MAX_NEWS_FILES)
            
            for file_path in self.data_dir.glob("daily_news_*.json"):
                try:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                    date_part = file_path.stem.replace('daily_news_', '')
                    file_date = datetime.strptime(date_part, '%Y-%m-%d')
                    
                    if file_date < cutoff_date:
                        file_path.unlink()
                        logger.info(f"–£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª –Ω–æ–≤–æ—Å—Ç–µ–π: {file_path.name}")
                        
                except (ValueError, OSError) as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {e}")
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤: {e}")
    
    def _collect_raw_news(self) -> Optional[str]:
        """
        –°–æ–±–∏—Ä–∞–µ—Ç —Å—ã—Ä—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ Perplexity Deep Research
        
        Returns:
            str: –°—ã—Ä–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç –æ—Ç API –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            prompt = get_perplexity_daily_collection_prompt()
            
            logger.info("üîç –ó–∞–ø—É—Å–∫–∞—é –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π...")
            logger.info("üìä –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ—Ç–≤–µ—Ç–∞: 8192 —Ç–æ–∫–µ–Ω–∞")
            
            payload = {
                "model": "sonar-deep-research",
                "messages": [
                    {
                        "role": "system",
                        "content": get_perplexity_system_prompt()
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                "max_tokens": PromptConfig.PERPLEXITY_COLLECTION_MAX_TOKENS,
                "temperature": PromptConfig.PERPLEXITY_TEMPERATURE,
                "top_p": PromptConfig.PERPLEXITY_TOP_P
            }
            
            import requests
            response = requests.post(
                config.PERPLEXITY_API_URL,
                headers={
                    "Authorization": f"Bearer {config.PERPLEXITY_API_KEY}",
                    "Content-Type": "application/json"
                },
                json=payload,
                timeout=config.REQUEST_TIMEOUT
            )
            
            response.raise_for_status()
            
            data = response.json()
            raw_content = data['choices'][0]['message']['content']
            
            logger.info("‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç Perplexity Deep Research")
            logger.info(f"üìè –†–∞–∑–º–µ—Ä –æ—Ç–≤–µ—Ç–∞: {len(raw_content)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            return raw_content
            
        except requests.exceptions.Timeout:
            logger.error("‚è∞ –ü—Ä–µ–≤—ã—à–µ–Ω —Ç–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –∫ Perplexity API")
            return None
        except requests.exceptions.RequestException as e:
            logger.error(f"üåê –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Perplexity API: {e}")
            return None
        except Exception as e:
            logger.error(f"üí• –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
            return None
    
    def _process_raw_content(self, raw_content: str) -> List[Dict]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—ã—Ä–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
        
        Args:
            raw_content: –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Deep Research
            
        Returns:
            List[Dict]: –°–ø–∏—Å–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
        """
        try:
            # –û—á–∏—â–∞–µ–º –æ—Ç —Ç–µ–≥–æ–≤ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
            if hasattr(self.perplexity_client, '_clean_deep_research_content'):
                cleaned_content = self.perplexity_client._clean_deep_research_content(raw_content)
            else:
                import re
                cleaned_content = re.sub(r'<think>.*?</think>', '', raw_content, flags=re.DOTALL)
                cleaned_content = re.sub(r'</?think>', '', cleaned_content)
            
            logger.debug(f"üìã –û—á–∏—â–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç:\n{cleaned_content[:500]}...")
            
            # –ü–∞—Ä—Å–∏–º –Ω–æ–≤–æ—Å—Ç–∏
            news_list = parse_collected_news(cleaned_content)
            
            logger.info(f"üì∞ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(news_list)} –Ω–æ–≤–æ—Å—Ç–µ–π")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫ –∫–∞–∂–¥–æ–π –Ω–æ–≤–æ—Å—Ç–∏
            current_time = datetime.now()
            schedule = config.PUBLICATION_SCHEDULE
            
            for i, news_item in enumerate(news_list):
                # –ù–∞–∑–Ω–∞—á–∞–µ–º –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
                if i < len(schedule):
                    news_item['scheduled_time'] = schedule[i]
                else:
                    # –ï—Å–ª–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –±–æ–ª—å—à–µ —á–µ–º –≤—Ä–µ–º–µ–Ω –≤ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–∏
                    news_item['scheduled_time'] = schedule[-1]  # –ü–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è
                
                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                news_item.update({
                    'id': f"news_{current_time.strftime('%Y%m%d')}_{i+1}",
                    'collected_at': current_time.isoformat(),
                    'published': False,
                    'publication_attempts': 0
                })
            
            return news_list
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {e}")
            return []
    
    def _save_news_to_file(self, news_list: List[Dict], date: datetime) -> bool:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –≤ JSON —Ñ–∞–π–ª
        
        Args:
            news_list: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            date: –î–∞—Ç–∞ –¥–ª—è –∫–æ—Ç–æ—Ä–æ–π —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –Ω–æ–≤–æ—Å—Ç–∏
            
        Returns:
            bool: True –µ—Å–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ—à–ª–æ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            file_path = self._get_news_file_path(date)
            
            news_data = {
                'date': date.strftime('%Y-%m-%d'),
                'collected_at': datetime.now().isoformat(),
                'total_news': len(news_list),
                'news': news_list
            }
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(news_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"üíæ –ù–æ–≤–æ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {file_path.name}")
            logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {len(news_list)} –Ω–æ–≤–æ—Å—Ç–µ–π")
            
            # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É
            for news in news_list:
                priority = news.get('priority', 0)
                title = news.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')[:50]
                time = news.get('scheduled_time', '–ù–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–æ')
                logger.info(f"  üìå –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç {priority} ({time}): {title}...")
            
            return True
            
        except Exception as e:
            logger.error(f"üíæ –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
            return False
    
    def collect_daily_news(self, target_date: Optional[datetime] = None) -> bool:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª —Å–±–æ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∞—Ç—É
        
        Args:
            target_date: –î–∞—Ç–∞ –¥–ª—è —Å–±–æ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–µ–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—á–µ—Ä–∞)
            
        Returns:
            bool: True –µ—Å–ª–∏ —Å–±–æ—Ä –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ
        """
        if target_date is None:
            target_date = datetime.now() - timedelta(days=1)  # –í—á–µ—Ä–∞
        
        logger.info("=" * 60)
        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ —Å–±–æ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ {target_date.strftime('%d.%m.%Y')}")
        logger.info("=" * 60)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å–æ–±–∏—Ä–∞–ª–∏ –ª–∏ —É–∂–µ –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ —ç—Ç—É –¥–∞—Ç—É
        file_path = self._get_news_file_path(target_date)
        if file_path.exists():
            logger.warning(f"‚ö†Ô∏è –§–∞–π–ª –Ω–æ–≤–æ—Å—Ç–µ–π —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {file_path.name}")
            logger.info("–î–ª—è –ø–µ—Ä–µ—Å–±–æ—Ä–∞ —É–¥–∞–ª–∏—Ç–µ —Ñ–∞–π–ª –≤—Ä—É—á–Ω—É—é")
            return False
        
        # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã
        self._cleanup_old_files()
        
        # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–±—Ä–∞—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
        for attempt in range(1, self.max_retries + 1):
            logger.info(f"üéØ –ü–æ–ø—ã—Ç–∫–∞ —Å–±–æ—Ä–∞ #{attempt}/{self.max_retries}")
            
            # –°–æ–±–∏—Ä–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
            raw_content = self._collect_raw_news()
            if not raw_content:
                if attempt < self.max_retries:
                    logger.info(f"‚è±Ô∏è –û–∂–∏–¥–∞–Ω–∏–µ {self.retry_delay} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π...")
                    import time
                    time.sleep(self.retry_delay)
                continue
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            news_list = self._process_raw_content(raw_content)
            if not news_list:
                logger.warning("üì∞ –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –æ—Ç–≤–µ—Ç–∞")
                if attempt < self.max_retries:
                    logger.info(f"‚è±Ô∏è –û–∂–∏–¥–∞–Ω–∏–µ {self.retry_delay} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π...")
                    import time
                    time.sleep(self.retry_delay)
                continue
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
            logger.info("üé® –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
            news_list_with_images = self._generate_images_for_news(news_list, target_date)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
            if self._save_news_to_file(news_list_with_images, target_date):
                logger.info("üéâ –°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
                logger.info("=" * 60)
                return True
            else:
                logger.error("üíæ –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞")
                if attempt < self.max_retries:
                    import time
                    time.sleep(self.retry_delay)
                continue
        
        logger.error("‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ —Å–±–æ—Ä–∞ –∏—Å—á–µ—Ä–ø–∞–Ω—ã")
        logger.info("=" * 60)
        return False
    
    def get_news_file_status(self, date: Optional[datetime] = None) -> Dict:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç—É—Å —Ñ–∞–π–ª–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∞—Ç—É
        
        Args:
            date: –î–∞—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—á–µ—Ä–∞)
            
        Returns:
            Dict: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç–∞—Ç—É—Å–µ —Ñ–∞–π–ª–∞
        """
        if date is None:
            date = datetime.now() - timedelta(days=1)
        
        file_path = self._get_news_file_path(date)
        
        if not file_path.exists():
            return {
                'exists': False,
                'date': date.strftime('%Y-%m-%d'),
                'file_path': str(file_path)
            }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            return {
                'exists': True,
                'date': date.strftime('%Y-%m-%d'),
                'file_path': str(file_path),
                'collected_at': data.get('collected_at'),
                'total_news': data.get('total_news', 0),
                'news_count': len(data.get('news', [])),
                'published_count': sum(1 for news in data.get('news', []) if news.get('published', False))
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return {
                'exists': True,
                'date': date.strftime('%Y-%m-%d'),
                'file_path': str(file_path),
                'error': str(e)
            }


def main():
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥—É–ª—è"""
    logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ NewsCollector...")
    
    collector = NewsCollector()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π
    success = collector.collect_daily_news()
    
    if success:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å
        status = collector.get_news_file_status()
        logger.info(f"üìä –°—Ç–∞—Ç—É—Å: {status}")
    else:
        logger.error("‚ùå –¢–µ—Å—Ç –Ω–µ –ø—Ä–æ—à–µ–ª")


if __name__ == "__main__":
    main()